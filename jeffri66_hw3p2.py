# -*- coding: utf-8 -*-
"""jeffri66_hw3p2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q9oAu4flk1L4G-CzJb9nG_HpXKRtHIGy
"""

# Commented out IPython magic to ensure Python compatibility.
import nltk
import pandas as pd
# %pip install ml-datasets
import ml_datasets
import pandas as pd
import numpy as np
# %pip install flaml
from flaml import AutoML
from flaml.automl.ml import sklearn_metric_loss_score
from sklearn.metrics import precision_score, recall_score

def make_features_lags_leads(sentence_df):
    sentence_features_df = pd.DataFrame(
        {
            "is_first_word": (sentence_df.index == 0).astype("float32"),
            "is_last_word": (sentence_df.index == (sentence_df.shape[0] - 1)).astype(
                "float32"
            ),
            "first_is_upper": sentence_df.word.str.istitle().astype("float32"),
            "all_are_upper": sentence_df.word.str.isupper().astype("float32"),
            "is_num": sentence_df.word.str.isnumeric().astype("float32"),
            "hyphen_is_present": sentence_df.word.str.contains("-").astype("float32"),
            "apostrophe_is_present": sentence_df.word.str.contains("'").astype(
                "float32"
            ),
            "exclam_is_present": sentence_df.word.str.contains("¡").astype("float32"),
            "ques_is_present": sentence_df.word.str.contains("¿").astype("float32"),
            "word_len": sentence_df.word.str.len().astype("float32"),
            "first_letter": sentence_df.word.str[0]
            .astype("category")
            .cat.codes.astype("float32"),
            "last_letter": sentence_df.word.str[-1]
            .astype("category")
            .cat.codes.astype("float32"),
        }
    )
    lag_features_df = sentence_features_df.shift(1, fill_value=None).add_prefix("lag_")
    lead_features_df = sentence_features_df.shift(-1, fill_value=None).add_prefix(
        "lead_"
    )
    return pd.concat([sentence_features_df, lag_features_df, lead_features_df], axis=1)


def make_features_array(X):
    sentences_dfs_list = []
    for sentence_list in X:
        sentence_df = pd.DataFrame(
            {"word": pd.Series(sentence_list, dtype="string")}
        ).pipe(make_features_lags_leads)
        sentences_dfs_list.append(sentence_df)
    return pd.concat(sentences_dfs_list).to_numpy(dtype="float32")


def get_y_as_array(y):
    sentences_pos_arrays_list = []
    for sentence_pos_array in y:
        flat_sentence_pos_array = sentence_pos_array.argmax(axis=1)
        sentences_pos_arrays_list.append(flat_sentence_pos_array)
    return np.concatenate(sentences_pos_arrays_list)


(train_X, train_Y), (dev_X, dev_Y) = ml_datasets.ud_ancora_pos_tags()
train_features_array = make_features_array(train_X)
train_y_array = get_y_as_array(train_Y)

auto = AutoML()
auto.fit(
    train_features_array,
    train_y_array,
    task="classification",
    time_budget=400,
    verbose=0,
    estimator_list=["xgboost"],
)
auto.best_config

test_features_array = make_features_array(dev_X)
test_y_array = get_y_as_array(dev_Y)
pred = auto.predict(test_features_array)

from sklearn.metrics import f1_score

metrics_dict = {
    "Accuracy": sklearn_metric_loss_score("accuracy", pred, test_y_array),
    "F1": f1_score(test_y_array, pred, average='micro'),
    "Precision": precision_score(test_y_array, pred, average='micro'),
    "Recall": recall_score(test_y_array, pred, average='micro'),
}
for metric, score in metrics_dict.items():
    print(f"{metric}: {score}")